# -*- coding: utf-8 -*-
"""Fashion_Product_Image_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OcDUrJpxSpI-p2jbxc9P0KaU_3wgtvIK

# ðŸ“š Fashion Product Image Classification

## Table of Contents

1. [Introduction](##introduction)
2. [Setup](#setup)
    - [Installing Required Libraries](#installing-required-libraries)
    - [Importing Libraries](#importing-libraries)
    - [Accessing and Downloading the Dataset](#accessing-and-downloading-the-dataset)
3. [Data Preparation and Analysis](#data-preparation-and-analysis)
    - [Defining Dataset Paths and Loading Data](#defining-dataset-paths-and-loading-data)
    - [Cleaning the Dataset](#cleaning-the-dataset)
    - [Analyzing the Dataset](#analyzing-the-dataset)
    - [Visualizing the Data](#visualizing-the-data)
4. [Data Transformation and Encoding](#data-transformation-and-encoding)
    - [Preparing Image IDs](#preparing-image-ids)
    - [Stratification for One-Hot Encoding](#stratification-for-one-hot-encoding)
    - [One-Hot Encoding](#one-hot-encoding)
    - [Splitting the Data into Training and Validation Sets](#splitting-the-data-into-training-and-validation-sets)
5. [Image Transformations and Custom Dataset Class](#image-transformations-and-custom-dataset-class)
    - [Defining Image Transformations](#defining-image-transformations)
    - [Creating Custom Dataset Class](#creating-custom-dataset-class)
    - [Creating Data Loaders](#creating-data-loaders)
    - [Checking Data Loader Outputs](#checking-data-loader-outputs)
    - [Visualizing a Batch of Training Data](#visualizing-a-batch-of-training-data)
6. [Model Definition and Training](#model-definition-and-training)
    - [Installing Additional Libraries](#installing-additional-libraries)
    - [Defining the Model Class](#defining-the-model-class)
    - [Training the Model](#training-the-model)
7. [Model Evaluation](#model-evaluation)
    - [Evaluating the Model](#evaluating-the-model)
    - [Calculating Accuracy](#calculating-accuracy)
    - [Saving the Best Model](#saving-the-best-model)
8. [Displaying Predictions](#displaying-predictions)
    - [Creating and Saving Label Dictionaries](#creating-and-saving-label-dictionaries)
    - [Displaying Sample Predictions](#displaying-sample-predictions)
    - [Predicting a Single Image](#predicting-a-single-image)
    - [Evaluating the Model on External Data](#evaluating-the-model-on-external-data)

## Introduction

Welcome to the Fashion Product Image Classification project! ðŸŽ‰ In this notebook, we will guide you through building a model that can predict various labels related to fashion products, such as gender, category, color, and season. We will use a comprehensive dataset of fashion product images and their corresponding attributes to train our model.

The growing e-commerce industry presents a wealth of data ready to be analyzed. This dataset includes high-resolution product images and multiple label attributes describing each product, manually entered during cataloging. Additionally, there is descriptive text commenting on the product characteristics, making this dataset particularly rich and versatile for various types of analysis and machine learning tasks.

Each product is identified by an ID, and there is a mapping in `styles.csv` to match these IDs with images in the `images/` directory. Key product categories and display names are also provided in the CSV file to help you get started easily.

## Setup

### 1. Installing Required Libraries

First, we need to install the necessary libraries for our project, including `torch`, `torchvision`, `pandas`, `matplotlib`, and `scikit-learn`.
"""

!pip install torch torchvision pandas matplotlib scikit-learn

!pip install pytorch-lightning
!pip install timm

"""### 2. Importing Libraries

Next, we'll import the essential libraries for data manipulation, image processing, and model training.
"""

import os
import pandas as pd
import torch
from torch.utils.data import Dataset, DataLoader
import torchvision
from torchvision import transforms
from PIL import Image
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from tqdm import tqdm
import torch.nn as nn
import torch.optim as optim
import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor
import timm
from pytorch_lightning.loggers import TensorBoardLogger
from sklearn.preprocessing import OneHotEncoder
import joblib

"""### 3. Accessing and Downloading the Dataset

we'll walk through the steps to mount Google Drive (if you're using Google Colab), install the Kaggle API, upload the Kaggle API key, and download the dataset from Kaggle.
"""

# Mount Google Drive to access the dataset (if using Google Colab)
from google.colab import drive
drive.mount('/content/drive')

# Install Kaggle API if not already installed
!pip install kaggle

# Set up Kaggle API key
from google.colab import files
files.upload()  # Upload kaggle.json

# Make a directory for the Kaggle API key
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/

# Set permissions for the key file
!chmod 600 ~/.kaggle/kaggle.json

# Download the dataset from Kaggle
!kaggle datasets download -d paramaggarwal/fashion-product-images-dataset
# !kaggle datasets download -d paramaggarwal/fashion-product-images-small

# Unzip the dataset
!unzip fashion-product-images-dataset.zip -d fashion_dataset_dataset
# !unzip fashion-product-images-small.zip -d fashion_dataset_small

gpu_info = !nvidia-smi
gpu_info = '\n'.join(gpu_info)
if gpu_info.find('failed') >= 0:
  print('Not connected to a GPU')
else:
  print(gpu_info)

"""## Data Preparation and Analyzing

### Defining Dataset Paths and Loading Data

we'll define the paths to the image directory and the CSV file containing the metadata, load the dataset into a pandas DataFrame, and display the first few rows of the dataset.
"""

ls

# Define the path to the dataset
# IMAGE_DIR = 'fashion_dataset_small/images'
# CSV_FILE = 'fashion_dataset_small/styles.csv'
IMAGE_DIR = 'fashion_dataset_dataset/fashion-dataset/images'
CSV_FILE = 'fashion_dataset_dataset/fashion-dataset/styles.csv'

# Load the dataset
data = pd.read_csv(CSV_FILE, on_bad_lines='skip')

# Display the first few rows of the dataset
print(data.head())

"""### Cleaning the Dataset

Next, we clean the dataset by removing entries with missing images.
"""

def clean_data(df, image_dir):
    valid_indices = []
    for index, row in tqdm(df.iterrows(), total=df.shape[0]):
        image_path = os.path.join(image_dir, f"{row['id']}.jpg")
        if os.path.exists(image_path):
            valid_indices.append(index)
    cleaned_df = df.loc[valid_indices].reset_index(drop=True)
    return cleaned_df

# Clean the dataset
data = clean_data(data, IMAGE_DIR)

print(f"Cleaned data shape: {data.shape}")

"""### Analyzing the Dataset

some basic analysis to understand the dataset's structure and content. then, We display the unique values for each categorical column to understand the different categories in our dataset.
"""

# Analyze the dataset
print(data.head())
print(data.describe(include='all'))
print(data.isnull().sum())
print(data.nunique())

# Display unique values in categorical columns
cat_columns = ['gender', 'masterCategory', 'subCategory', 'articleType', 'baseColour', 'season', 'usage']
for col in cat_columns:
    print(f"Unique values in {col}: {data[col].unique()}")
    print('--------------------------------------')

"""### Visualizing

we create a function to visualize the distribution of categorical columns and then We call the `display_sample_images` function to visualize some sample images and their labels.
"""

# Set up matplotlib and seaborn
plt.style.use('ggplot')
sns.set(style='whitegrid')

# Function to plot the distribution of categorical columns
def plot_category_distribution(column_name):
    plt.figure(figsize=(10, 6))
    sns.countplot(y=column_name, data=data, order=data[column_name].value_counts().index)
    plt.title(f'Distribution of {column_name}')
    plt.show()

for col in cat_columns:
    plot_category_distribution(col)

"""### Preparing Image IDs

We will append the file extension .jpg to each image ID to match the filenames in the image directory.
"""

data['id'] = data['id'].astype(str) + '.jpg'

data

# Display sample images along with their labels
def display_sample_images(data, image_dir, num_samples=32):
    sample_data = data.sample(num_samples)
    plt.figure(figsize=(25, 20))
    for idx, row in enumerate(sample_data.iterrows()):
        img_path = os.path.join(image_dir, row[1]['id'])  # No need to add '.jpg' again
        if os.path.exists(img_path):
            img = Image.open(img_path).convert('RGB')
            plt.subplot(4, 8, idx + 1)
            plt.imshow(img)
            plt.title(
                f"{row[1]['gender']}\n"
                f"{row[1]['masterCategory']}\n"
                f"{row[1]['subCategory']}\n"
                f"{row[1]['articleType']}\n"
                f"{row[1]['baseColour']}\n"
                f"{row[1]['season']}\n"
                f"{row[1]['usage']}",
                fontsize=14, weight='bold', pad=10
            )
            plt.axis('off')
            plt.gca().add_patch(plt.Rectangle((0, 0), img.width, img.height, linewidth=2, edgecolor='black', facecolor='none'))
    plt.subplots_adjust(wspace=0.5, hspace=1.0)
    plt.show()

display_sample_images(data, IMAGE_DIR)

"""## Data Transformation and Encoding

### Stratification for One-Hot Encoding

We will create a combined stratification column before applying one-hot encoding to the categorical columns. This helps in maintaining the distribution of categories in the dataset.
"""

# Define the categorical columns
cat_columns = ['gender', 'masterCategory', 'subCategory', 'articleType', 'baseColour', 'season', 'usage']

# Initial Analysis
def initial_analysis(data, columns):
    print("Initial Data Analysis:")
    print("First few rows of the dataset:")
    print(data.head())
    print("\nUnique values in each categorical column:")
    for col in columns:
        print(f"{col}: {data[col].nunique()}")
    print("\nMissing values in each column:")
    print(data.isnull().sum())

# Replace Rare Labels with Null
def replace_rare_labels(data, columns, threshold=500):
    for col in columns:
        value_counts = data[col].value_counts()
        rare_labels = value_counts[value_counts < threshold].index
        data[col] = data[col].apply(lambda x: None if x in rare_labels else x)
    return data

# Post-Processing Analysis
def post_processing_analysis(data, columns):
    print("\nPost-Processing Data Analysis:")
    print("First few rows of the modified dataset:")
    print(data.head())
    print("\nUnique values in each categorical column:")
    for col in columns:
        print(f"{col}: {data[col].nunique()}")
    print("\nMissing values in each column:")
    print(data.isnull().sum())

# Assuming 'data' is your dataset
# Perform initial analysis
initial_analysis(data, cat_columns)

# Apply the function to the dataset
data = replace_rare_labels(data, cat_columns, threshold=500)

# Replace NaN values with None
data = data.where(pd.notnull(data), None)

# Perform post-processing analysis
post_processing_analysis(data, cat_columns)

# Create a combined stratification column with handling of null values
def create_stratify_col(row, columns):
    return '_'.join([str(row[col]) if row[col] is not None else 'null' for col in columns])

# Create stratification column
data['stratify_col'] = data.apply(lambda row: create_stratify_col(row, cat_columns), axis=1)

# Filter out classes with fewer than 2 members
strat_counts = data['stratify_col'].value_counts()
valid_strat_classes = strat_counts[strat_counts > 1].index
filtered_data = data[data['stratify_col'].isin(valid_strat_classes)]

# Data with fewer than 2 members in stratification class
rare_class_data = data[~data['stratify_col'].isin(valid_strat_classes)]

filtered_data

rare_class_data

# # Create a combined stratification column before one-hot encoding
# cat_columns = ['gender', 'masterCategory', 'subCategory', 'articleType', 'baseColour', 'season', 'usage']
# data['stratify_col'] = data.apply(lambda row: '_'.join([str(row[col]) for col in cat_columns]), axis=1)

# # Identify rare stratification classes
# rare_stratify_classes = data['stratify_col'].value_counts()[data['stratify_col'].value_counts() < 50].index.tolist()

# # Remove rare classes from the dataset
# data = data[~data['stratify_col'].isin(rare_stratify_classes)]

"""### One-Hot Encoding

apply one-hot encoding to the categorical columns to convert them into a format suitable for model training.
"""

# Initialize OneHotEncoder
onehot_encoder = OneHotEncoder(sparse=False)

# Fit and transform the categorical columns
encoded_data = onehot_encoder.fit_transform(filtered_data[cat_columns])

# Create a DataFrame for the one-hot encoded columns
encoded_columns = onehot_encoder.get_feature_names_out(cat_columns)
encoded_df = pd.DataFrame(encoded_data, columns=encoded_columns)

# Concatenate the original dataframe with the one-hot encoded columns
filtered_data = pd.concat([filtered_data.reset_index(drop=True), encoded_df.reset_index(drop=True)], axis=1)

# Drop the original categorical columns
filtered_data.drop(columns=cat_columns, inplace=True)

# Display the first few rows of the dataset to ensure columns are encoded
print(filtered_data.head())

# Save the one-hot encoder for future use
joblib.dump(onehot_encoder, 'onehot_encoder.pkl')

data

"""### Splitting the Data into Training and Validation Sets

We will split the dataset into training and validation sets, ensuring the stratification is maintained.
"""

from sklearn.model_selection import train_test_split

# Split the data into training and validation sets
train_data, val_data = train_test_split(filtered_data, test_size=0.20, stratify=filtered_data['stratify_col'], random_state=42)

# Drop the stratification column as it's no longer needed
train_data.drop(columns=['stratify_col'], inplace=True)
val_data.drop(columns=['stratify_col'], inplace=True)

# Add the rare_class_data back to the train_data
# Perform one-hot encoding for the rare_class_data
encoded_rare_data = onehot_encoder.transform(rare_class_data[cat_columns])
encoded_rare_df = pd.DataFrame(encoded_rare_data, columns=encoded_columns)

# Concatenate the original rare_class_data with the one-hot encoded columns
rare_class_data = pd.concat([rare_class_data.reset_index(drop=True), encoded_rare_df.reset_index(drop=True)], axis=1)
rare_class_data.drop(columns=cat_columns + ['stratify_col'], inplace=True)

# Add rare_class_data to train_data
train_data = pd.concat([train_data, rare_class_data], ignore_index=True)

# Verify the splits
print(f'Training set: {train_data.shape}')
print(f'Validation set: {val_data.shape}')

train_data

# Define the categorical columns
cat_columns = ['gender', 'masterCategory', 'subCategory', 'articleType', 'baseColour', 'season', 'usage']

# Function to analyze and visualize the distribution of classes in one-hot encoded columns
def visualize_distribution(train_data, val_data, columns):
    num_cols = 2
    num_rows = (len(columns) + 1) // num_cols

    fig, axes = plt.subplots(num_rows, num_cols, figsize=(18, num_rows * 6))
    axes = axes.flatten()

    for idx, col in enumerate(columns):
        col_names = [c for c in train_data.columns if col in c]

        # Training set distribution
        train_distribution = train_data[col_names].sum()

        # Validation set distribution
        val_distribution = val_data[col_names].sum()

        # Expected validation distribution based on training data (25%)
        expected_val_distribution = train_distribution * 0.25

        # Plot the distributions
        sns.barplot(x=train_distribution.index, y=train_distribution.values, ax=axes[idx], color='blue', alpha=0.6, label='Train')
        sns.barplot(x=val_distribution.index, y=val_distribution.values, ax=axes[idx], color='orange', alpha=0.6, label='Validation')

        # Plot the expected validation distribution as a dashed line
        axes[idx].plot(expected_val_distribution.index, expected_val_distribution.values, 'r--', label='Expected Validation (25% of Train)')

        axes[idx].set_title(f'{col} Distribution')
        axes[idx].set_xticks(range(len(train_distribution.index)))
        axes[idx].set_xticklabels(train_distribution.index, rotation=90)
        axes[idx].legend()

    # Remove empty subplots
    for i in range(len(columns), len(axes)):
        fig.delaxes(axes[i])

    plt.tight_layout()
    plt.show()

# Visualize the distribution in the training and validation sets
visualize_distribution(train_data, val_data, cat_columns)

# Drop non-numeric columns from training and validation datasets
train_data = train_data.drop(columns=['year', 'productDisplayName'])
val_data = val_data.drop(columns=['year', 'productDisplayName'])

train_data

"""###  Image Transformations and Custom Dataset Class

In this step, we will define the necessary image transformations and create a custom dataset class to handle our data efficiently.
"""

import multiprocessing

# Get the number of available CPU cores
num_workers = multiprocessing.cpu_count()
print(f"Number of available CPU cores: {num_workers}")

import pandas as pd
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import os
import torch
from fastai.vision.all import PILImage

# Define image transformations
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Custom dataset class
class FashionDataset(Dataset):
    def __init__(self, dataframe, image_dir, transform=None):
        self.dataframe = dataframe
        self.image_dir = image_dir
        self.transform = transform

    def __len__(self):
        return len(self.dataframe)

    def __getitem__(self, idx):
        # Keep the 'id' column for image file names
        img_name = os.path.join(self.image_dir, self.dataframe.iloc[idx]['id'])
        # image = Image.open(img_name).convert('RGB')
        image = PILImage.create(img_name)

        # Drop the 'id' column when creating the labels tensor
        labels = self.dataframe.iloc[idx].drop(labels=['id']).values.astype('float')

        if self.transform:
            image = self.transform(image)

        return image, torch.tensor(labels)

# Create datasets
train_dataset = FashionDataset(train_data, IMAGE_DIR, transform=transform)
val_dataset = FashionDataset(val_data, IMAGE_DIR, transform=transform)

# Create dataloaders with multiple workers
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=num_workers, pin_memory=True)
val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=num_workers, pin_memory=True)

"""#### Checking Data Loader Outputs

We will check the shape of the data batches and ensure there are no NaN values in our training and validation sets.
"""

# Checking Data Loader Outputs
# Check the shapes of the data
for images, labels in train_loader:
    print("Image batch shape:", images.shape)
    print("Labels batch shape:", labels.shape)
    break

for images, labels in val_loader:
    print("Image batch shape:", images.shape)
    print("Labels batch shape:", labels.shape)
    break

# Check for any NaN values
print("Training Data NaNs:")
print(train_data.isna().sum())
print("Validation Data NaNs:")
print(val_data.isna().sum())

"""#### Visualizing a Batch of Training Data

We will visualize a batch of training data to ensure that our data loading and transformations are working correctly.
"""

import matplotlib.pyplot as plt
import numpy as np
import torch
import torchvision

# Visualization function
def imshow(image, ax=None, title=None):
    if ax is None:
        fig, ax = plt.subplots()
    image = image.numpy().transpose((1, 2, 0))
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    image = std * image + mean
    image = np.clip(image, 0, 1)
    ax.imshow(image)
    if title is not None:
        ax.set_title(title)
    plt.pause(0.001)

# Decode labels using label_dicts
def decode_labels(label_vector, label_dicts):
    decoded_labels = {}
    start_idx = 0
    for col, categories in label_dicts.items():
        end_idx = start_idx + len(categories)
        label_slice = label_vector[start_idx:end_idx]
        decoded_label = categories[torch.argmax(label_slice).item()]
        decoded_labels[col] = decoded_label
        start_idx = end_idx
    return decoded_labels

# Check the shapes of the data
for images, labels in train_loader:
    print("Image batch shape:", images.shape)
    print("Labels batch shape:", labels.shape)
    break

# Get a batch of training data
inputs, classes = next(iter(train_loader))

# Make a grid from batch
out = torchvision.utils.make_grid(inputs)

# Plot the images in the batch, along with the labels
imshow(out)

"""### Creating and Saving Label Dictionaries

We will create dictionaries for each column label and save them for future use.
"""

# Assuming 'data' is your DataFrame and 'cat_columns' are the categorical columns
cat_columns = ['gender', 'masterCategory', 'subCategory', 'articleType', 'baseColour', 'season', 'usage']

# Extract the column names of the one-hot encoded columns
onehot_columns = [col for col in train_data.columns if any(c in col for c in cat_columns)]

# Create dictionaries for each column label
label_dicts = {}
for col in cat_columns:
    label_dicts[col] = [col_name.split('_', 1)[1] for col_name in onehot_columns if col in col_name]

# Save the label dictionaries
joblib.dump(label_dicts, '/content/drive/MyDrive/Roshan/new/label_dicts.pkl')

label_dicts

# Visualize a single image and its labels
def visualize_single_image(image, label_vector, label_dicts):
    decoded_labels = decode_labels(label_vector, label_dicts)
    imshow(image, title=", ".join([f"{k}: {v}" for k, v in decoded_labels.items()]))
    print("Decoded labels for the selected image:")
    for key, value in decoded_labels.items():
        print(f"{key}: {value}")

print("Raw class labels for the first image in the batch:")
print(classes[0])
# Visualize the first image in the batch
visualize_single_image(inputs[0], classes[0], label_dicts)

# Define the mask for None labels based on the label_dicts
def create_none_label_mask(label_dicts):
    none_mask = []
    for category, labels in label_dicts.items():
        none_idx = labels.index('None') if 'None' in labels else -1
        category_mask = [1.0] * len(labels)
        if none_idx != -1:
            category_mask[none_idx] = 0.0
        none_mask.extend(category_mask)
    return torch.tensor(none_mask)

none_label_mask = create_none_label_mask(label_dicts)

none_label_mask

# Save the mask to the specified location
joblib.dump(none_label_mask, '/content/drive/MyDrive/Roshan/new/none_label_mask.pkl')

"""## Model Definition and Training

### Installing Required Libraries

Before defining and training the model, we need to install additional libraries: pytorch-lightning and timm.

### Defining the Model Class

We define a custom model class using PyTorch Lightning to handle the training and validation loops efficiently. The model architecture is based on the EfficientNet-B3 model from the timm library, with a custom classifier layer for our specific number of classes.
"""

import torch
import torch.nn as nn
import torch.optim as optim
import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from pytorch_lightning.strategies import DDPStrategy
from pytorch_lightning.plugins import MixedPrecisionPlugin
import timm
import joblib
import numpy as np
from collections import defaultdict

class FashionModel(pl.LightningModule):
    def __init__(self, num_classes, none_label_mask, label_dicts, freeze_backbone=True):
        super(FashionModel, self).__init__()
        self.model = timm.create_model('efficientnet_b3', pretrained=True)

        # Freeze the backbone layers if specified
        if freeze_backbone:
            for param in self.model.parameters():
                param.requires_grad = False

        # Replace the classifier
        self.model.classifier = nn.Sequential(
            nn.Linear(self.model.classifier.in_features, 1024),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(1024, num_classes)
        )

        self.criterion = nn.BCEWithLogitsLoss(reduction='none')
        self.none_label_mask = none_label_mask
        self.label_dicts = label_dicts
        self.num_classes = num_classes

        # Accumulators for logging
        self.train_accumulated_correct = defaultdict(int)
        self.train_accumulated_total = defaultdict(int)
        self.val_accumulated_correct = defaultdict(int)
        self.val_accumulated_total = defaultdict(int)
        self.train_total_correct = 0
        self.train_total_samples = 0
        self.val_total_correct = 0
        self.val_total_samples = 0

    def forward(self, x):
        return self.model(x)

    def compute_loss(self, outputs, labels):
        # Check for infinities in outputs
        outputs = torch.clamp(outputs, min=-10, max=10)
        if torch.isinf(outputs).any():
            print("Found inf in outputs after clamping")
        loss = self.criterion(outputs, labels)
        if torch.isnan(loss).any() or torch.isinf(loss).any():
            print("Found nan or inf in loss computation")
        mask = self.none_label_mask.to(labels.device)
        loss = loss * mask
        loss = loss.sum() / mask.sum()
        return loss

    def calculate_classwise_accuracy(self, outputs, labels, accumulated_correct, accumulated_total):
        start_idx = 0
        for col, categories in self.label_dicts.items():
            end_idx = start_idx + len(categories)
            preds = (torch.sigmoid(outputs[:, start_idx:end_idx]) > 0.5).float()
            correct = (preds == labels[:, start_idx:end_idx]).sum().item()
            total = labels[:, start_idx:end_idx].numel()
            accumulated_correct[col] += correct
            accumulated_total[col] += total
            start_idx = end_idx

    def log_classwise_accuracy(self, accumulated_correct, accumulated_total, prefix):
        for col in self.label_dicts.keys():
            acc = accumulated_correct[col] / accumulated_total[col]
            self.log(f'{prefix}_{col}_accuracy', acc, on_epoch=True, prog_bar=True, logger=True)

    def training_step(self, batch, batch_idx):
        images, labels = batch
        if torch.isnan(images).any() or torch.isnan(labels).any():
            print(f"Found nan in training data at batch {batch_idx}")
        outputs = self(images)
        loss = self.compute_loss(outputs, labels)
        self.log('train_loss', loss.mean(), on_step=True, on_epoch=True, prog_bar=True, logger=True)

        # Accumulate class-wise accuracy
        self.calculate_classwise_accuracy(outputs, labels, self.train_accumulated_correct, self.train_accumulated_total)

        # Calculate total accuracy for this batch
        preds = (torch.sigmoid(outputs) > 0.5).float()
        correct = (preds == labels).sum().item()
        total = labels.numel()
        self.train_total_correct += correct
        self.train_total_samples += total

        return loss.mean()

    def validation_step(self, batch, batch_idx):
        images, labels = batch
        if torch.isnan(images).any() or torch.isnan(labels).any():
            print(f"Found nan in validation data at batch {batch_idx}")
        outputs = self(images)
        outputs = torch.clamp(outputs, min=-10, max=10)
        if torch.isnan(outputs).any() or torch.isinf(outputs).any():
            print(f"Found nan or inf in outputs at batch {batch_idx}")
        loss = self.compute_loss(outputs, labels)
        if torch.isnan(loss).any() or torch.isinf(loss).any():
            print(f"Found nan or inf in validation loss at batch {batch_idx}")
            print(f"Outputs: {outputs}")
            print(f"Labels: {labels}")
        self.log('val_loss', loss.mean(), on_step=True, on_epoch=True, prog_bar=True, logger=True)

        # Accumulate class-wise accuracy
        self.calculate_classwise_accuracy(outputs, labels, self.val_accumulated_correct, self.val_accumulated_total)

        # Calculate total accuracy for this batch
        preds = (torch.sigmoid(outputs) > 0.5).float()
        correct = (preds == labels).sum().item()
        total = labels.numel()
        self.val_total_correct += correct
        self.val_total_samples += total

        return loss.mean()

    def on_train_epoch_end(self):
        # Log class-wise accuracy at the end of the epoch
        self.log_classwise_accuracy(self.train_accumulated_correct, self.train_accumulated_total, 'train')

        # Log total accuracy at the end of the epoch
        train_total_accuracy = self.train_total_correct / self.train_total_samples
        self.log('train_total_accuracy', train_total_accuracy, on_epoch=True, prog_bar=True, logger=True)

        # Reset accumulators
        self.train_accumulated_correct = defaultdict(int)
        self.train_accumulated_total = defaultdict(int)
        self.train_total_correct = 0
        self.train_total_samples = 0

    def on_validation_epoch_end(self):
        # Log class-wise accuracy at the end of the epoch
        self.log_classwise_accuracy(self.val_accumulated_correct, self.val_accumulated_total, 'val')

        # Log total accuracy at the end of the epoch
        val_total_accuracy = self.val_total_correct / self.val_total_samples
        self.log('val_total_accuracy', val_total_accuracy, on_epoch=True, prog_bar=True, logger=True)

        # Reset accumulators
        self.val_accumulated_correct = defaultdict(int)
        self.val_accumulated_total = defaultdict(int)
        self.val_total_correct = 0
        self.val_total_samples = 0

    def configure_optimizers(self):
        optimizer = optim.AdamW(self.parameters(), lr=0.00005, weight_decay=0.01)  # Further reduced learning rate
        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)
        return [optimizer], [scheduler]

### train

# Load the mask and label dictionaries

none_label_mask = joblib.load('/content/drive/MyDrive/Roshan/new/none_label_mask.pkl')
label_dicts = joblib.load('/content/drive/MyDrive/Roshan/new/label_dicts.pkl')

# Assuming train_loader and val_loader are already defined and set up
num_classes = 77  # update this based on the actual number of one-hot encoded labels
model = FashionModel(num_classes, none_label_mask, label_dicts)

# Checkpoint callback to save the best model
checkpoint_callback = ModelCheckpoint(
    monitor='val_loss',
    mode='min',
    save_top_k=2,
    verbose=True,
    dirpath='/content/drive/MyDrive/Roshan/new',  # Save the model to this directory
    filename='best_model-{epoch:02d}-{val_loss:.2f}'
)

# Learning rate monitor to log learning rate changes
lr_monitor = LearningRateMonitor(logging_interval='epoch')

# Early stopping callback to stop training when the model stops improving
early_stopping_callback = EarlyStopping(
    monitor='val_loss',
    patience=15,
    verbose=True,
    mode='min'
)

# TensorBoard logger for better visualization
logger = TensorBoardLogger("/content/drive/MyDrive/Roshan/new/tb_logs", name="fashion_model")

# Determine the number of devices
num_devices = torch.cuda.device_count() if torch.cuda.is_available() else 1

# Trainer
trainer_args = {
    'max_epochs': 80,
    'accelerator': 'gpu' if torch.cuda.is_available() else 'cpu',
    'devices': num_devices,
    'precision': 32,  # Use full precision to avoid numerical instability
    'callbacks': [checkpoint_callback, lr_monitor, early_stopping_callback],
    'logger': logger,
    'gradient_clip_val': 0.5  # Add gradient clipping
}

if num_devices > 1:
    trainer_args['strategy'] = DDPStrategy(find_unused_parameters=False)

trainer = pl.Trainer(**trainer_args)

import multiprocessing

# Get the number of available CPU cores
num_workers = multiprocessing.cpu_count()
print(f"Number of available CPU cores: {num_workers}")

torch.cuda.device_count()

# Train the model
trainer.fit(model, train_loader, val_loader)

"""## Model Evaluation"""

ls

# Path to the TensorBoard logs
log_dir = "/content/drive/MyDrive/Roshan/new/tb_logs/fashion_model/version_0"  # Ensure this path matches your logging path

def extract_metrics(log_dir):
    event_files = [os.path.join(log_dir, d) for d in os.listdir(log_dir) if 'events' in d]
    if not event_files:
        raise FileNotFoundError(f"No event files found in {log_dir}")

    # Load the TensorBoard event accumulator
    ea = event_accumulator.EventAccumulator(event_files[0])
    ea.Reload()

    # Extract metrics
    metrics = {}
    for tag in ea.Tags()['scalars']:
        metrics[tag] = pd.DataFrame(ea.Scalars(tag)).set_index('step')['value']

    return metrics

def plot_main_metrics(metrics, main_metric_pairs, title, figsize=(20, 8)):
    sns.set(style="whitegrid")
    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=figsize)

    for i, (train_metric, val_metric) in enumerate(main_metric_pairs):
        if train_metric in metrics and val_metric in metrics:
            axes[i].plot(metrics[train_metric], label='Train', color='b')
            axes[i].plot(metrics[val_metric], label='Validation', color='r')
            axes[i].set_xlabel('Epochs', fontsize=14)
            if 'loss' in train_metric:
                axes[i].set_ylabel('Loss', fontsize=14)
                axes[i].set_title('Loss over Epochs', fontsize=16)
            else:
                axes[i].set_ylabel('Accuracy', fontsize=14)
                axes[i].set_title('Accuracy over Epochs', fontsize=16)
            axes[i].legend(fontsize=12)
            axes[i].grid(True)

    plt.tight_layout()
    plt.suptitle(title, fontsize=18, weight='bold')
    plt.subplots_adjust(top=0.85)
    plt.show()

def plot_class_metrics(metrics, class_metric_pairs, title, nrows, ncols, figsize=(20, 20)):
    sns.set(style="whitegrid")
    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)
    axes = axes.flatten()

    for i, (train_metric, val_metric) in enumerate(class_metric_pairs):
        if train_metric in metrics and val_metric in metrics:
            axes[i].plot(metrics[train_metric], label='Train', color='b')
            axes[i].plot(metrics[val_metric], label='Validation', color='r')
            axes[i].set_xlabel('Epochs', fontsize=12)
            axes[i].set_ylabel('Accuracy', fontsize=12)
            metric_name = train_metric.split("_")[1].capitalize() + ' Accuracy'
            axes[i].set_title(metric_name, fontsize=14)
            axes[i].legend(fontsize=10)
            axes[i].grid(True)

    # Remove any empty subplots
    for j in range(i + 1, len(axes)):
        fig.delaxes(axes[j])

    plt.tight_layout()
    plt.suptitle(title, fontsize=18, weight='bold')
    plt.subplots_adjust(top=0.95)
    plt.show()

# Extract metrics
metrics = extract_metrics(log_dir)

# Define pairs of main metrics to plot
main_metric_pairs = [
    ('train_loss_epoch', 'val_loss_epoch'),
    ('train_total_accuracy', 'val_total_accuracy')
]

# Define pairs of class metrics to plot
class_metric_pairs = [
    ('train_gender_accuracy', 'val_gender_accuracy'),
    ('train_masterCategory_accuracy', 'val_masterCategory_accuracy'),
    ('train_subCategory_accuracy', 'val_subCategory_accuracy'),
    ('train_articleType_accuracy', 'val_articleType_accuracy'),
    ('train_baseColour_accuracy', 'val_baseColour_accuracy'),
    ('train_season_accuracy', 'val_season_accuracy'),
    ('train_usage_accuracy', 'val_usage_accuracy')
]

# Plot main metrics
plot_main_metrics(metrics, main_metric_pairs, 'Training and Validation Main Metrics')

# Plot class metrics
plot_class_metrics(metrics, class_metric_pairs, 'Training and Validation Class Metrics', nrows=3, ncols=3, figsize=(18, 18))

"""### Evaluating the Model on train and validation (from the dataset)

We will evaluate the model by loading TensorBoard logs, plotting the training and validation losses, and calculating accuracy. This helps us understand the model's performance over the training epochs.
"""

import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report
import torch
import joblib
import numpy as np

# Load label dictionaries and mask
label_dicts = joblib.load('/content/drive/MyDrive/Roshan/new/label_dicts.pkl')
none_label_mask = joblib.load('/content/drive/MyDrive/Roshan/new/none_label_mask.pkl')

# Define the path to the model checkpoint
checkpoint_path = '/content/drive/MyDrive/Roshan/new/best_model-epoch=23-val_loss=5.23.ckpt'

# Load the model
model = FashionModel.load_from_checkpoint(checkpoint_path,
                                           num_classes=len(label_dicts['gender']) +
                                                      len(label_dicts['masterCategory']) +
                                                      len(label_dicts['subCategory']) +
                                                      len(label_dicts['articleType']) +
                                                      len(label_dicts['baseColour']) +
                                                      len(label_dicts['season']) +
                                                      len(label_dicts['usage']),
                                           none_label_mask=none_label_mask,
                                           label_dicts=label_dicts)

# Move the model to the appropriate device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Function to evaluate the model on the loader
def evaluate_model(loader, model, device, label_dicts):
    model.to(device)
    model.eval()

    all_labels = []
    all_predictions = []

    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            predictions = (torch.sigmoid(outputs) > 0.5).float()

            all_labels.append(labels.cpu().numpy())
            all_predictions.append(predictions.cpu().numpy())

    all_labels = np.concatenate(all_labels, axis=0)
    all_predictions = np.concatenate(all_predictions, axis=0)

    return all_labels, all_predictions

# Function to generate a detailed report and plots
def generate_classwise_report(labels, predictions, label_dicts):
    class_metrics = {col: {'precision': [], 'recall': [], 'f1': []} for col in label_dicts.keys()}

    start_idx = 0
    for col, categories in label_dicts.items():
        end_idx = start_idx + len(categories)
        class_labels = labels[:, start_idx:end_idx]
        class_predictions = predictions[:, start_idx:end_idx]

        # Exclude samples with 'None' label for this class
        none_idx = categories.index('None') if 'None' in categories else None
        if none_idx is not None:
            mask = class_labels[:, none_idx] == 0
            class_labels = class_labels[mask]
            class_predictions = class_predictions[mask]

        for i, category in enumerate(categories):
            if category == 'None':
                continue
            y_true = class_labels[:, i]
            y_pred = class_predictions[:, i]
            precision = precision_score(y_true, y_pred, zero_division=0)
            recall = recall_score(y_true, y_pred, zero_division=0)
            f1 = f1_score(y_true, y_pred, zero_division=0)
            class_metrics[col]['precision'].append(precision)
            class_metrics[col]['recall'].append(recall)
            class_metrics[col]['f1'].append(f1)

        start_idx = end_idx

    return class_metrics

def plot_classwise_metrics(train_metrics, val_metrics, label_dicts):
    categories = [category for col in label_dicts.values() for category in col if category != 'None']

    train_precisions = []
    val_precisions = []
    train_recalls = []
    val_recalls = []
    train_f1s = []
    val_f1s = []

    for col in label_dicts.keys():
        train_precisions.extend(train_metrics[col]['precision'])
        val_precisions.extend(val_metrics[col]['precision'])
        train_recalls.extend(train_metrics[col]['recall'])
        val_recalls.extend(val_metrics[col]['recall'])
        train_f1s.extend(train_metrics[col]['f1'])
        val_f1s.extend(val_metrics[col]['f1'])

    x = np.arange(len(categories))
    width = 0.35

    fig, ax = plt.subplots(3, 1, figsize=(20, 30))

    ax[0].bar(x - width/2, train_precisions, width, label='Train', color='b')
    ax[0].bar(x + width/2, val_precisions, width, label='Validation', color='r')
    ax[0].set_ylabel('Precision')
    ax[0].set_title('Class-wise Precision')
    ax[0].set_xticks(x)
    ax[0].set_xticklabels(categories, rotation=90)
    ax[0].legend()

    ax[1].bar(x - width/2, train_recalls, width, label='Train', color='b')
    ax[1].bar(x + width/2, val_recalls, width, label='Validation', color='r')
    ax[1].set_ylabel('Recall')
    ax[1].set_title('Class-wise Recall')
    ax[1].set_xticks(x)
    ax[1].set_xticklabels(categories, rotation=90)
    ax[1].legend()

    ax[2].bar(x - width/2, train_f1s, width, label='Train', color='b')
    ax[2].bar(x + width/2, val_f1s, width, label='Validation', color='r')
    ax[2].set_ylabel('F1 Score')
    ax[2].set_title('Class-wise F1 Score')
    ax[2].set_xticks(x)
    ax[2].set_xticklabels(categories, rotation=90)
    ax[2].legend()

    fig.tight_layout()
    plt.show()

# Evaluate on training set
train_labels, train_predictions = evaluate_model(train_loader, model, device, label_dicts)
train_metrics = generate_classwise_report(train_labels, train_predictions, label_dicts)

# Evaluate on validation set
val_labels, val_predictions = evaluate_model(val_loader, model, device, label_dicts)
val_metrics = generate_classwise_report(val_labels, val_predictions, label_dicts)

# Save the calculated metrics
metrics_save_path = '/content/drive/MyDrive/Roshan/new/'

# Function to save metrics
def save_metrics(metrics, filename):
    filepath = os.path.join(metrics_save_path, filename)
    joblib.dump(metrics, filepath)

# Save train and validation metrics
save_metrics(train_metrics, 'train_metrics.pkl')
save_metrics(val_metrics, 'val_metrics.pkl')

# # Function to load metrics
# def load_metrics(filename):
#     filepath = os.path.join(metrics_save_path, filename)
#     return joblib.load(filepath)

# # Load the saved metrics
# train_metrics = load_metrics('train_metrics.pkl')
# val_metrics = load_metrics('val_metrics.pkl')

# Function to extract F1 scores from the saved metrics
def extract_f1_scores(metrics):
    f1_scores = {col: [] for col in metrics.keys()}
    for col, categories in metrics.items():
        for i, f1_score in enumerate(categories['f1']):
            f1_scores[col].append(f1_score)
    return f1_scores


# Function to plot class-wise F1 scores
def plot_classwise_f1_scores(f1_scores_train, f1_scores_val, label_dicts):
    for col, categories in label_dicts.items():
        if 'None' in categories:
            categories.remove('None')

        train_scores = f1_scores_train[col]
        val_scores = f1_scores_val[col]

        fig, ax = plt.subplots(figsize=(12, 6))
        indices = np.arange(len(categories))
        width = 0.35

        ax.bar(indices - width/2, train_scores, width, label='Train', color='b')
        ax.bar(indices + width/2, val_scores, width, label='Validation', color='r')

        ax.set_ylabel('F1 Score')
        ax.set_title(f'Class-wise F1 Scores for {col}')
        ax.set_xticks(indices)
        ax.set_xticklabels(categories, rotation=45, ha='right')
        ax.legend()
        sns.despine()

        plt.show()

# Extract F1 scores from the loaded metrics
f1_scores_train = extract_f1_scores(train_metrics)
f1_scores_val = extract_f1_scores(val_metrics)

# Plot class-wise F1 scores using the extracted F1 scores
plot_classwise_f1_scores(f1_scores_train, f1_scores_val, label_dicts)

import torch
import numpy as np
import matplotlib.pyplot as plt
from torchvision.utils import make_grid
import joblib

def decode_predictions(predictions, label_dicts):
    decoded_labels = []
    for pred in predictions:
        sample_labels = {}
        start_idx = 0
        for col, categories in label_dicts.items():
            end_idx = start_idx + len(categories)
            sample_pred = pred[start_idx:end_idx]
            label = categories[np.argmax(sample_pred)]
            sample_labels[col] = label
            start_idx = end_idx
        decoded_labels.append(sample_labels)
    return decoded_labels

# Function to denormalize the images
def denormalize(image, mean, std):
    mean = np.array(mean)
    std = np.array(std)
    image = image.numpy().transpose((1, 2, 0))
    image = std * image + mean
    image = np.clip(image, 0, 1)
    return image

# Function to display images with their predicted and actual labels
def display_predictions(loader, model, label_dicts, num_samples=5):
    model.eval()  # Set the model to evaluation mode
    images, labels = next(iter(loader))  # Get a batch of images and labels
    images = images[:num_samples]
    labels = labels[:num_samples]

    with torch.no_grad():
        outputs = model(images.to(device)).cpu().numpy()

    decoded_predictions = decode_predictions(outputs, label_dicts)
    decoded_labels = decode_predictions(labels.numpy(), label_dicts)

    mean = [0.485, 0.456, 0.406]
    std = [0.229, 0.224, 0.225]

    # Plot each image with predicted and actual labels
    for img, pred, actual in zip(images, decoded_predictions, decoded_labels):
        plt.figure(figsize=(5, 5))
        img = denormalize(img, mean, std)
        plt.imshow(img)
        plt.title(f"Actual:\n{actual}\n\nPredicted:\n{pred}")
        plt.axis('off')
        plt.show()

# Display predictions for training samples
print("Training Samples Predictions:")
display_predictions(train_loader, model, label_dicts, num_samples=5)

# Display predictions for validation samples
print("Validation Samples Predictions:")
display_predictions(val_loader, model, label_dicts, num_samples=5)

"""### Evaluating the Model on foreign data"""

import torch
import numpy as np
import matplotlib.pyplot as plt
import joblib
from PIL import Image
from torchvision import transforms
from google.colab import files

# Load label dictionaries and mask
label_dicts = joblib.load('/content/drive/MyDrive/Roshan/new/label_dicts.pkl')
none_label_mask = joblib.load('/content/drive/MyDrive/Roshan/new/none_label_mask.pkl')

# Define the path to the model checkpoint
checkpoint_path = '/content/drive/MyDrive/Roshan/new/best_model-epoch=23-val_loss=5.23.ckpt'

# Load the model
model = FashionModel.load_from_checkpoint(checkpoint_path,
                                           num_classes=len(label_dicts['gender']) +
                                                      len(label_dicts['masterCategory']) +
                                                      len(label_dicts['subCategory']) +
                                                      len(label_dicts['articleType']) +
                                                      len(label_dicts['baseColour']) +
                                                      len(label_dicts['season']) +
                                                      len(label_dicts['usage']),
                                           none_label_mask=none_label_mask,
                                           label_dicts=label_dicts)

# Move the model to the appropriate device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Function to preprocess and predict a single image
def predict_image(image_path, model, label_dicts, transform, device):
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0)  # Add batch dimension
    image = image.to(device)
    with torch.no_grad():
        output = model(image)
    probabilities = torch.sigmoid(output).cpu().numpy()[0]
    decoded_prediction = decode_predictions([probabilities], label_dicts)[0]
    return decoded_prediction

# Decode predictions
def decode_predictions(predictions, label_dicts):
    decoded_labels = []
    for pred in predictions:
        sample_labels = {}
        start_idx = 0
        for col, categories in label_dicts.items():
            end_idx = start_idx + len(categories)
            sample_pred = pred[start_idx:end_idx]
            label = categories[np.argmax(sample_pred)]
            sample_labels[col] = label
            start_idx = end_idx
        decoded_labels.append(sample_labels)
    return decoded_labels

# Function to display image with predictions
def display_prediction(image_path, prediction):
    image = Image.open(image_path)
    plt.figure(figsize=(10, 10))

    formatted_prediction = '\n'.join([f"{key}: {value}" for key, value in prediction.items()])
    plt.text(0.5, 0.98, f"Predicted Labels:\n{formatted_prediction}", fontsize=14, ha='center', va='top', wrap=True)

    plt.imshow(image)
    plt.axis('off')
    plt.show()

# Function to upload an image
def upload_image():
    uploaded = files.upload()
    for filename in uploaded.keys():
        return filename

# Main function to run the prediction and display
def main():
    image_path = upload_image()
    if image_path:
        prediction = predict_image(image_path, model, label_dicts, transform, device)
        display_prediction(image_path, prediction)

if __name__ == "__main__":
    main()

if __name__ == "__main__":
    main()

if __name__ == "__main__":
    main()